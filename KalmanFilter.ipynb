{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2036abc9-14aa-4229-82e0-8d44c87199d2",
   "metadata": {},
   "source": [
    "First, some definitions. I am following [this chapter](https://nbviewer.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/08-Designing-Kalman-Filters.ipynb) of Kalman and Bayesian Filters in Python to give me some structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084192d4-9c29-4b8c-8f03-db258523bf56",
   "metadata": {},
   "source": [
    "## Choose State Variables\n",
    "I first need to define my x. \n",
    "\n",
    "$\\textbf{x}$ consists of the PM2.5 values, wind x and wind y components in a given square. So, this would be 80x50x3 or 12000 dimensions. woof.\n",
    "\n",
    "I think I'll say the matrix is structured as follows:\n",
    "\n",
    "$$\\textbf{x} = \\begin{pmatrix} P_0 & x_0 & y_0 & P_1 & x_1 & y_1 & \\cdots & P_n & x_n & y_n \\end{pmatrix}^T$$\n",
    "\n",
    "Hopefully this makes reading the covariance matrices easier, but maybe it won't. I don't know yet.\n",
    "\n",
    "For the following math, I will be calculating 2D matrices of P, x, and y with 80 rows and 50 columns (as defined by the CMAQ data) and then smushing them together later, because that'll work a lot better for my brain. Also that way, I can change how $\\textbf{x}$ is structured if this way is doo-doo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d127bc6e-41e4-4bf7-ac93-a4842e8b2aa7",
   "metadata": {},
   "source": [
    "## Design State Transition Function\n",
    "\n",
    "Ok, first difficult problem, how to define $\\textbf F$, where:\n",
    "$${\\textbf x}_k = \\textbf F  {\\textbf x}_{k-1}$$\n",
    "\n",
    "I don't need an exact equation, but something as close as possible so that the optimization algorithm can have a decent starting point.\n",
    "\n",
    "### For the PM2.5 values:\n",
    "\n",
    "I want to use the 5x5 grid surrounding a square as the estimators.\n",
    "\n",
    "For a given square like (3,3), the equation will be $$\\sum_{i=1}^5 \\sum_{j=1}^5 \\sqrt{ab} * P_{ij}$$ \n",
    "where $a = 1 - \\frac{|\\text{ideal\\_angle} - \\text{actual\\_angle}|}{\\pi}$, $\\text{ideal\\_angle} = \\tan^{-1} (\\frac{-(3-j)}{(3-i)})$, $\\text{actual\\_angle} = \\tan^{-1} (\\frac{w_y}{w_x})$, $b=\\frac1{(3-i)^2 + (3-j)^2}$.\n",
    "\n",
    "In summary, I'm doing a weighted average of PM values from the surrounding 5x5 squares, where the weights are a geometric mean between a measure from 0 to 1 of whether the wind vector is pointing at the target square (1) or not (0), and an inverse squared distance, where 1 is the closest distance (directly adjacent) and it goes down to 0 from there. The purpose of the geometric mean is so that low values of wind are heavily penalized in the overall weight.\n",
    "\n",
    "All together (where the next value of $P_{ij}$ is determined from the previous time step's $P_{ij}$ values):\n",
    "\n",
    "$$\\sum_{i=1}^5 \\sum_{j=1}^5 \\sqrt{\\left(1 - \\frac{|\\tan^{-1} (\\frac{-(3-j)}{(3-i)}) - \\tan^{-1} (\\frac{w_y}{w_x})|}{\\pi}\\right)\\left(\\frac1{(3-i)^2 + (3-j)^2}\\right)} * P_{ij}$$ \n",
    "\n",
    "Woof. Oh and obviously the weights are going to be normalized by the sum of all of the weights for that square. \n",
    "\n",
    "Also, for the squares that actually have sensors within them, I want to have those mostly trust the sensor values, with maybe a bit of wind influence (like 10\\% maybe?).\n",
    "\n",
    "So for when i and j equal the value, I'll throw out the above calculated weight and instead do 9 times the sum of the other weights.\n",
    "\n",
    "### For the wind values:\n",
    "\n",
    "I think a similar sort of inverse distance weighting would work, so something like (for the (3,3) square):\n",
    "\n",
    "$$\\sum_{i=1}^5 \\sum_{j=1}^5 \\frac1{(3-i)^2 + (3-j)^2} * \\bar{w}$$\n",
    "\n",
    "Where $\\bar{w} = \\begin{pmatrix} w_x & w_y \\end{pmatrix}^T$ (the x and y components of the wind)\n",
    "\n",
    "Similar to before where the weights are normalized by the sum of all of the weights, and when there's actually a wind sensor in the square it'll increase the weight on it by a lot.\n",
    "\n",
    "I have to figure out how to express this as a product of matrices, so that'll be fun. I'm gonna avoid that until after dinner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0bb113-1016-4e3f-99f9-88568eab754d",
   "metadata": {},
   "source": [
    "## Design the Process Noise Matrix\n",
    "Now I have to make $\\textbf Q$, which is the covariance matrix of uncertainty for the values in x, i.e. they describe the $\\sigma$ of each $\\mu$ for every value of $\\textbf{x}$, as well as covariances between all variables. This is kind of a pain. I'll have to estimate covariance of both the PM values and the wind components. Thankfully the algorithm will correct my guesses over time, but I need a decent measure.\n",
    "\n",
    "Ok, I obviously want the squares with actual sensors in them to have the lowest variances (not zero because then the algorithm trusts them too much), maybe like $0.5^2$ based on the range of the PM values\n",
    "\n",
    "Then, the squares with estimates should be graded on how many of the 5x5 squares are from actual PM values, and the $\\sigma$ estimate scales higher with less actual sensors, up to a point where if all 5x5 squares are estimated, then the covariance is extremely high, like $8^2$? \n",
    "\n",
    "Ok, so let's say $e(x,y) = I(\\text{does index xy has a valid PM sensor in it?})$, so a 1 if it does have data, and a 0 if not. For the diagonals of the covariance matrix (which are just variance measurements):\n",
    "\n",
    "$$ \\sigma_{i,j}^2 = \n",
    "\\begin{cases} \n",
    "0.5^2 & e(i,j) = 1 \\\\ \n",
    "(\\frac{7.5}{24} * (24 - \\sum_{k=i-2, k \\neq i}^{i+2} \\sum_{l=j-2, l \\neq j}^{j+2} e(k,l)) + 0.5)^2& e(i,j) = 0 \n",
    "\\end{cases}$$\n",
    "\n",
    "The $\\frac{7.5}{24}$ and $0.5$ changes the range of the inner function from $[0,24]$ to $[0.5, 8]$, which seems reasonable to me for a $\\sigma$ value for this dataset.\n",
    "\n",
    "Then, for the off-diagonals, I need to assume some covariance. I don't really know what they'll be, but I can make some guesses and the algorithm will correct those guesses over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca9e5f-7643-4149-b1b6-e0c6a9e26a7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
