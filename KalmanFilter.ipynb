{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2036abc9-14aa-4229-82e0-8d44c87199d2",
   "metadata": {},
   "source": [
    "Fkrst, some definitions. I am following [this chapter](https://nbviewer.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/08-Designing-Kalman-Filters.ipynb) of Kalman and Bayesian Filters in Python to give me some structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084192d4-9c29-4b8c-8f03-db258523bf56",
   "metadata": {},
   "source": [
    "## Choose State Variables\n",
    "I first need to define my x. \n",
    "\n",
    "$\\textbf{x}$ consists of the PM2.5 values, wind x and wind y components in a given square. So, this would be 80x50x3 or 12000 values. woof.\n",
    "\n",
    "I think I'll say the matrix is structured as follows:\n",
    "\n",
    "$$\\textbf{x} = \\begin{pmatrix} P_{0 0} & P_{0 1} & \\cdots & P_{i j} & x_{0 0} & x_{0 1} & \\cdots & x_{i j} & y_{0 0} & y_{0 1} & \\cdots & y_{ij} \\end{pmatrix}^T$$\n",
    "\n",
    "For the following math, I will be calculating 2D matrices of P, x, and y with 80 rows and 50 columns (as defined by the CMAQ data) and then smushing them together later, because that'll work a lot better for my brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d20e21-3451-4a59-9f10-e2fa0f13936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3555d231-76a6-4f1c-a43b-b4b83d08b26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4383, 50, 80)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4383, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "windX = np.load('meteostat/windX_array.npy')\n",
    "windY = np.load('meteostat/windY_array.npy')\n",
    "windXdates = pd.read_csv('meteostat/windXdates.csv')\n",
    "windYdates = pd.read_csv('meteostat/windYdates.csv')\n",
    "display(windX.shape)\n",
    "display(windXdates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8224a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3712fc25-3941-4c46-8d90-fdcdf182a971",
       "rows": [
        [
         "0",
         "0",
         "2010-01-01"
        ],
        [
         "1",
         "1",
         "2010-01-02"
        ],
        [
         "2",
         "2",
         "2010-01-03"
        ],
        [
         "3",
         "3",
         "2010-01-04"
        ],
        [
         "4",
         "4",
         "2010-01-05"
        ],
        [
         "5",
         "5",
         "2010-01-06"
        ],
        [
         "6",
         "6",
         "2010-01-07"
        ],
        [
         "7",
         "7",
         "2010-01-08"
        ],
        [
         "8",
         "8",
         "2010-01-09"
        ],
        [
         "9",
         "9",
         "2010-01-10"
        ],
        [
         "10",
         "10",
         "2010-01-11"
        ],
        [
         "11",
         "11",
         "2010-01-12"
        ],
        [
         "12",
         "12",
         "2010-01-13"
        ],
        [
         "13",
         "13",
         "2010-01-14"
        ],
        [
         "14",
         "14",
         "2010-01-15"
        ],
        [
         "15",
         "15",
         "2010-01-16"
        ],
        [
         "16",
         "16",
         "2010-01-17"
        ],
        [
         "17",
         "17",
         "2010-01-18"
        ],
        [
         "18",
         "18",
         "2010-01-19"
        ],
        [
         "19",
         "19",
         "2010-01-20"
        ],
        [
         "20",
         "20",
         "2010-01-21"
        ],
        [
         "21",
         "21",
         "2010-01-22"
        ],
        [
         "22",
         "22",
         "2010-01-23"
        ],
        [
         "23",
         "23",
         "2010-01-24"
        ],
        [
         "24",
         "24",
         "2010-01-25"
        ],
        [
         "25",
         "25",
         "2010-01-26"
        ],
        [
         "26",
         "26",
         "2010-01-27"
        ],
        [
         "27",
         "27",
         "2010-01-28"
        ],
        [
         "28",
         "28",
         "2010-01-29"
        ],
        [
         "29",
         "29",
         "2010-01-30"
        ],
        [
         "30",
         "30",
         "2010-01-31"
        ],
        [
         "31",
         "31",
         "2010-02-01"
        ],
        [
         "32",
         "32",
         "2010-02-02"
        ],
        [
         "33",
         "33",
         "2010-02-03"
        ],
        [
         "34",
         "34",
         "2010-02-04"
        ],
        [
         "35",
         "35",
         "2010-02-05"
        ],
        [
         "36",
         "36",
         "2010-02-06"
        ],
        [
         "37",
         "37",
         "2010-02-07"
        ],
        [
         "38",
         "38",
         "2010-02-08"
        ],
        [
         "39",
         "39",
         "2010-02-09"
        ],
        [
         "40",
         "40",
         "2010-02-10"
        ],
        [
         "41",
         "41",
         "2010-02-11"
        ],
        [
         "42",
         "42",
         "2010-02-12"
        ],
        [
         "43",
         "43",
         "2010-02-13"
        ],
        [
         "44",
         "44",
         "2010-02-14"
        ],
        [
         "45",
         "45",
         "2010-02-15"
        ],
        [
         "46",
         "46",
         "2010-02-16"
        ],
        [
         "47",
         "47",
         "2010-02-17"
        ],
        [
         "48",
         "48",
         "2010-02-18"
        ],
        [
         "49",
         "49",
         "2010-02-19"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4383
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>4378</td>\n",
       "      <td>2021-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>4379</td>\n",
       "      <td>2021-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>4380</td>\n",
       "      <td>2021-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>4381</td>\n",
       "      <td>2021-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>4382</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4383 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        time\n",
       "0         0  2010-01-01\n",
       "1         1  2010-01-02\n",
       "2         2  2010-01-03\n",
       "3         3  2010-01-04\n",
       "4         4  2010-01-05\n",
       "...     ...         ...\n",
       "4378   4378  2021-12-27\n",
       "4379   4379  2021-12-28\n",
       "4380   4380  2021-12-29\n",
       "4381   4381  2021-12-30\n",
       "4382   4382  2021-12-31\n",
       "\n",
       "[4383 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put index in its own column, to eventually subset the windX and windY dateframes\n",
    "windXdates = windXdates.reset_index()\n",
    "windXdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b90c63-f85b-4cd8-bdd5-a40e8b8b36fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 50, 80)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(365, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2010\n",
    "PM25 = np.load(f'PM2.5/{year}PM_array.npy')\n",
    "PM25dates = pd.read_csv(f'PM2.5/{year}PMdates.csv')\n",
    "display(PM25.shape)\n",
    "display(PM25dates.shape)\n",
    "# flattens down the columns first, then the rows\n",
    "PM25flat = PM25[0,:,:].flatten('F')\n",
    "PM25flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fd738c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "Name: index, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset windX and windY by the dates that are in PM25\n",
    "PM25datesmerge = PM25dates.merge(windXdates, how='left', left_on='Date Local', right_on='time')\n",
    "display(PM25datesmerge.loc[0:2, 'index'])\n",
    "windXYear = windX[PM25datesmerge['index'],:,:]\n",
    "windYYear = windY[PM25datesmerge['index'],:,:]\n",
    "windXYear.shape\n",
    "\n",
    "windXYearflat = windXYear[0,:,:].flatten('F')\n",
    "windYYearflat = windYYear[0,:,:].flatten('F')\n",
    "windXYearflat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e4a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's an example x vector, stacking them together\n",
    "x = np.hstack((PM25flat, windXYearflat, windYYearflat))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8ee6ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10598"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d127bc6e-41e4-4bf7-ac93-a4842e8b2aa7",
   "metadata": {},
   "source": [
    "## Design State Transition Function\n",
    "\n",
    "Ok, first difficult problem, how to define $\\textbf F$, where:\n",
    "$${\\textbf x}_k = \\textbf F  {\\textbf x}_{k-1}$$\n",
    "\n",
    "I don't need an exact equation, but something as close as possible so that the optimization algorithm can have a decent starting point.\n",
    "\n",
    "### For the PM2.5 values:\n",
    "\n",
    "I want to use the 5x5 grid surrounding a square as the estimators.\n",
    "\n",
    "For a given square like (3,3), the equation will be $$\\sum_{i=1}^5 \\sum_{j=1}^5 \\sqrt{ab} * P_{ij}$$ \n",
    "where $a = 1 - \\frac{|\\text{ideal\\_angle} - \\text{actual\\_angle}|}{\\pi}$, $\\text{ideal\\_angle} = \\tan^{-1} (\\frac{-(3-j)}{(3-i)})$, $\\text{actual\\_angle} = \\tan^{-1} (\\frac{w_y}{w_x})$, $b=\\frac1{(3-i)^2 + (3-j)^2}$.\n",
    "\n",
    "In summary, I'm doing a weighted average of PM values from the surrounding 5x5 squares, where the weights are a geometric mean between a measure from 0 to 1 of whether the wind vector is pointing at the target square (1) or not (0), and an inverse squared distance, where 1 is the closest distance (directly adjacent) and it goes down to 0 from there. The purpose of the geometric mean is so that low values of wind are heavily penalized in the overall weight.\n",
    "\n",
    "All together (where the next value of $P_{ij}$ is determined from the previous time step's $P_{ij}$ values):\n",
    "\n",
    "$${P_{ij}}_{new} = \\sum_{k=i-2}^{i+2} \\sum_{l=j-2}^{j+2} \\sqrt{\\left(1 - \\frac{|\\tan^{-1} (\\frac{-(3-l)}{(3-k)}) - \\tan^{-1} (\\frac{w_y}{w_x})|}{\\pi}\\right)\\left(\\frac1{(3-k)^2 + (3-l)^2}\\right)} * P_{kl}$$ \n",
    "\n",
    "Woof. Oh and obviously the weights are going to be normalized by the sum of all of the weights for that square.\n",
    "\n",
    "Also, for the squares that actually have sensors within them, I want to have those mostly trust the sensor values, with maybe a bit of wind influence (like 10\\% maybe?).\n",
    "\n",
    "So for when i and j equal the value, I'll throw out the above calculated weight and instead do 9 times the sum of the other weights.\n",
    "\n",
    "MUST DOUBLE CHECK THE OUTPUT OF THE SUBTRACTION\n",
    "\n",
    "Then, I'll construct $\\textbf F$ for the PM2.5 values with the above calculations (combined with the below wind calculations).\n",
    "\n",
    "Soooo... I realized that the function above cannot be expressed in terms of a linear function, so I'm going to transition into unscented kalman filter instead, which should be fine I think.\n",
    "\n",
    "So then, ${\\textbf x}_k = \\textbf F(  {\\textbf x}_{k-1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4ef1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "804b4c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7168146928204138"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 % (2 * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "89fbcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def mat_to_flat(row, col, shape:list):\n",
    "    ### converts matrix coordinates to the flat coordinates\n",
    "    return (col * shape[0]) + row\n",
    "\n",
    "# fix angle wraparound difference issue\n",
    "# gives absolute smallest difference between two angles, outputs values from 0 to pi\n",
    "def abs_diff_wraparound(a,b):\n",
    "    return abs(math.atan2(math.sin(a - b), math.cos(a - b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x, dt=1):\n",
    "    row = PM25.shape[1]\n",
    "    col = PM25.shape[2]\n",
    "\n",
    "    size = row * col\n",
    "\n",
    "    # Extract PM, wind x, and wind y from the x vector\n",
    "    PM = x[:size].reshape(row, col, order='F')\n",
    "    w_x = x[size:2*size].reshape(row, col, order='F')\n",
    "    w_y = x[2*size:].reshape(row, col, order='F')\n",
    "\n",
    "    PM_new = np.zeros_like(PM)\n",
    "\n",
    "    # i and j denote the current square whose weights are being calculated\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            # create 5x5 grid of squares surrounding i,j square, except on the edges where it cuts off\n",
    "            weights = np.zeroes((5,5)).flatten()\n",
    "            w = 0\n",
    "            \n",
    "            # k and l denote the \"target\" square that will be a part of the weighted average\n",
    "            low_k = i - 2 if i - 2 >= 0 else 0\n",
    "            high_k = i + 2 if i + 2 <= PM25.shape[1] else PM25.shape[1] - 1\n",
    "            low_l = j - 2 if j - 2 >= 0 else 0\n",
    "            high_l = j + 2 if j + 2 <= PM25.shape[2] else PM25.shape[2] - 1\n",
    "            for k in range(low_k, high_k+1):\n",
    "                for l in range(low_l, high_l+1):\n",
    "\n",
    "                    # find difference between ideal angle between target and current\n",
    "                    ideal_ang = math.atan2(-(j-l)/(i-k))\n",
    "                    actual_ang = math.atan2(w_y[k,l]/w_x[k,l])\n",
    "                    a = 1 - (abs_diff_wraparound(ideal_ang,actual_ang) / np.pi)\n",
    "\n",
    "                    # find inverse square distance between target and current\n",
    "                    b = 1 / ((i-k)**2 + (j-l)**2)\n",
    "                    \n",
    "                    # geometric mean of a and b\n",
    "                    weights[w] = (a*b)**0.5\n",
    "                    w += 1\n",
    "    return PM_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "faee8e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "ideal: x: 2, y: -2, ang: -0.7853981633974483\n",
      "actual: x: 1, y: -1, ang: -0.7853981633974483\n",
      "a: 1.00, b: 0.12\n",
      "(0, 4)\n",
      "ideal: x: 2, y: 2, ang: 0.7853981633974483\n",
      "actual: x: 0, y: 1, ang: 1.5707963267948966\n",
      "a: 0.75, b: 0.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.35355339, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.30618622, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PM = np.array([[10, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, np.nan, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [1000, 0, 0, 0, 0]])\n",
    "\n",
    "w_x = np.array([[1, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0]])\n",
    "\n",
    "w_y = np.array([[-1, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [1, 0, 0, 0, 0]])\n",
    "\n",
    "# create 5x5 grid of squares surrounding i,j square, except on the edges where it cuts off\n",
    "weights = np.zeros((5,5)).flatten()\n",
    "w = 0\n",
    "\n",
    "i = 2\n",
    "j = 2\n",
    "\n",
    "# y and x denote the \"target\" square that will be a part of the weighted average\n",
    "low_y = i - 2 if i - 2 >= 0 else 0\n",
    "high_y = i + 2 if i + 2 <= PM25.shape[1] else PM25.shape[1] - 1\n",
    "low_x = j - 2 if j - 2 >= 0 else 0\n",
    "high_x = j + 2 if j + 2 <= PM25.shape[2] else PM25.shape[2] - 1\n",
    "for y in range(low_y, high_y+1):\n",
    "    for x in range(low_x, high_x+1):\n",
    "        if y == i and x == j:\n",
    "            weights[w] = 0\n",
    "            w += 1\n",
    "            continue\n",
    "        \n",
    "        if w_y[y,x] == 0 and w_x[y,x] == 0:\n",
    "            weights[w] = 0\n",
    "            w += 1\n",
    "            continue\n",
    "        \n",
    "        print(f'({x}, {y})')\n",
    "        # find difference between ideal angle between target and current\n",
    "        ideal_ang = math.atan2(-(j-y),(i-x))\n",
    "        print(f'ideal: x: {(i-x)}, y: {-(j-y)}, ang: {ideal_ang}')\n",
    "        actual_ang = math.atan2(w_y[y,x],w_x[y,x])\n",
    "        print(f'actual: x: {w_x[y,x]}, y: {w_y[y,x]}, ang: {actual_ang}')\n",
    "        a = 1 - (abs_diff_wraparound(ideal_ang,actual_ang) / np.pi)\n",
    "\n",
    "        # find inverse square distance between target and current\n",
    "        b = 1 / ((i-y)**2 + (j-x)**2)\n",
    "        \n",
    "        print(f'a: {a:.2f}, b: {b:.2f}')\n",
    "        # geometric mean of a and b\n",
    "        weights[w] = (a*b)**0.5\n",
    "        w += 1\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ffe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: make a matrix of weights (the sqrt ab), where each row is a given square (0-3999) and the columns describe the weight contributing to the estimate\n",
    "vecLength = PM25.shape[1] * PM25.shape[2]\n",
    "F_pm = np.zeros((vecLength,vecLength))\n",
    "for i in range(PM25.shape[1]):\n",
    "    for j in range(PM25.shape[2]):\n",
    "        # create 5x5 grid of squares surrounding i,j square, except on the edges where it cuts off\n",
    "        low_k = i - 2 if i - 2 >= 0 else 0\n",
    "        high_k = i + 2 if i + 2 <= PM25.shape[1] else PM25.shape[1]\n",
    "        low_l = j - 2 if j - 2 >= 0 else 0\n",
    "        high_l = j + 2 if j + 2 <= PM25.shape[2] else PM25.shape[2]\n",
    "        for k in range(low_k, high_k):\n",
    "            for l in range(low_l, high_l):\n",
    "                a = 1 - abs(math.atan2(-(3-l)/(3-k)) - math.atan2())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7a940",
   "metadata": {},
   "source": [
    "\n",
    "### For the wind values:\n",
    "\n",
    "I think a similar sort of inverse distance weighting would work, so something like (for the (3,3) square):\n",
    "\n",
    "$$\\sum_{i=1}^5 \\sum_{j=1}^5 \\frac1{(3-i)^2 + (3-j)^2} * \\bar{w}$$\n",
    "\n",
    "Where $\\bar{w} = \\begin{pmatrix} w_x & w_y \\end{pmatrix}^T$ (the x and y components of the wind)\n",
    "\n",
    "Similar to before where the weights are normalized by the sum of all of the weights, and when there's actually a wind sensor in the square it'll increase the weight on it by a lot.\n",
    "\n",
    "I have to figure out how to express this as a product of matrices, so that'll be fun. I'm gonna avoid that until after dinner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83634315-b95c-4bcc-b322-4b9e78bdde5d",
   "metadata": {},
   "source": [
    "## Design the Process Noise Matrix\n",
    "Now I have to make $\\textbf Q$, which is the covariance matrix of uncertainty for the values in x, i.e. they describe the $\\sigma$ of each $\\mu$ for every value of $\\textbf{x}$, as well as covariances between all variables. This is kind of a pain. I'll have to estimate covariance of both the PM values and the wind components. Thankfully the algorithm will correct my guesses over time, but I need a decent measure.\n",
    "\n",
    "Ok, I obviously want the squares with actual sensors in them to have the lowest variances (not zero because then the algorithm trusts them too much), maybe like $0.5^2$ based on the range of the PM values\n",
    "\n",
    "Then, the squares with estimates should be graded on how many of the 5x5 squares are from actual PM values, and the $\\sigma$ estimate scales higher with less actual sensors, up to a point where if all 5x5 squares are estimated, then the covariance is extremely high, like $8^2$? \n",
    "\n",
    "Ok, so let's say $e(x,y) = I(\\text{does index xy has a valid PM sensor in it?})$, so a 1 if it does have data, and a 0 if not. For the diagonals of the covariance matrix (which are just variance measurements):\n",
    "\n",
    "$$ \\sigma_{i,j}^2 = \n",
    "\\begin{cases} \n",
    "0.5^2 & e(i,j) = 1 \\\\ \n",
    "(\\frac{7.5}{24} * (24 - \\sum_{k=i-2, k \\neq i}^{i+2} \\sum_{l=j-2, l \\neq j}^{j+2} e(k,l)) + 0.5)^2& e(i,j) = 0 \n",
    "\\end{cases}$$\n",
    "\n",
    "The $\\frac{7.5}{24}$ and $0.5$ changes the range of the inner function from $[0,24]$ to $[0.5, 8]$, which seems reasonable to me for a $\\sigma$ value for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0d048-0a88-441b-b835-08d9336a392d",
   "metadata": {},
   "source": [
    "Then, for the off-diagonals, I need to assume some covariance. I don't really know what they'll be, but I can make some guesses and the algorithm will correct those guesses over time.\n",
    "\n",
    "Since $cov(x,y) \\leq \\sqrt{var(x)* var(y)}$ by Cauchy-Scwhartz, the covariance between two squares must follow that inequality. How about I say that the covariance is maximum ( when they are next to each other, and tapers off linearly until 0? What would be a valid distance where the pollution would be unrelated?\n",
    "\n",
    "Ok, I'll base it on normal wind speed, which is less than 20 mph, or 32 km/hr. This means that pollution could potentially travel 768 kilometers in 24 hours... which is a lot. The squares are 36km, so that would span 21 squares. Eek. I'm gonna just say 10 squares and call it there.\n",
    "\n",
    "So, $\\text{cov}(P_{ij}, P_{kl}) = w_{ijkl} * \\sqrt{var(P_{ij})* var(P_{kl})}$, where \n",
    "$$w_{ijkl} = \\begin{cases} \n",
    "\\frac{9 - (|i-k| + |k-l|)}{9} & |i-k| + |k-l| <= 9 \\\\ \n",
    "0 & |i-k| + |k-l| \\geq 10 = 0 \n",
    "\\end{cases}$$\n",
    "\n",
    "So, $w_{ijkl}$ is 1 when directly adjacent squares, then decreases by $\\frac19$ for each square away.\n",
    "\n",
    "I think I'll do similar for the wind as well, probably with different estimated variances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edfeff-259d-4cd1-9c37-3ab4ef7f9f82",
   "metadata": {},
   "source": [
    "# Design the Measurement Function\n",
    "Now I need to design $\\textbf H$, the measurement function that converts $\\textbf x$ into the shape of $\\textbf z$, the measurements. I think this design is critical, because the measurement vector $\\textbf z$ will likely be changing shape as stations gain data and lose data. The structure is $\\textbf z = \\textbf H \\textbf x$, so H will have (# of measurements) rows and (80x50x3) columns.\n",
    "\n",
    "I think it's pretty simple, just select the correct x value for each sensor value.\n",
    "\n",
    "Given square (0,0) and (0,2) have sensors, and (0,1) does not, the conversion from $\\textbf x$ to measurement would just have to skip (0,1), since it wouldn't have a sensor value.\n",
    "So:\n",
    "$$\\begin{align*}\n",
    "zP_{00} &= 1 * P_{00} + 0 * x_{00} + 0 * y_{00} + 0 * P_{01} + \\cdots \\\\\n",
    "zx_{00} &= 0 * P_{00} + 1 * x_{00} + 0 * y_{00} + 0 * P_{01} + \\cdots \\\\\n",
    "zy_{00} &= 0 * P_{00} + 0 * x_{00} + 1 * y_{00} + 0 * P_{01} + \\cdots \\\\\n",
    "zP_{02} &= 0 * P_{00} + 0 * x_{00} + 0 * y_{00} + \\cdots + 1 * P_{02}\n",
    "\\end{align*}$$\n",
    "\n",
    "$$\\textbf H = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 &\\cdots \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 &\\cdots \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 &\\cdots \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 &\\cdots \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 &\\cdots \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 &\\cdots \\\\\n",
    "\\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots &\\cdots\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Then, $\\textbf H$ should be able to be changed as the number of measurements changes. I hope. I *think* this will work with the equations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b6ea3-bb7d-496b-938e-bcc59153fcf9",
   "metadata": {},
   "source": [
    "# Design the Measurement Noise Matrix\n",
    "I now make the covariance matrix $\\textbf R$ that describes the variance and covariances of the measurements in $\\textbf z$. I will assume that the sensors have independent noise. I have no idea what the actual variance of these sensors are, so maybe I'll just steal from above.\n",
    "\n",
    "Let's say PM sensors have a variance of $0.5^2$ and wind sensors have variance of $2^2$. This is totally arbitrary and I'll probably tune this later. So, R will be a diag matrix with $0.5^2$, $2^2$, and $2^2$ repeating for each sensor value in $\\textbf z$.\n",
    "\n",
    "$$\\textbf R = \\begin{bmatrix}\n",
    "\\sigma_{P_{00}} & 0 & 0 & \\cdots\\\\\n",
    "0 & \\sigma_{x_{00}} & 0 & \\cdots\\\\\n",
    "0 & 0 & \\sigma_{y_{00}} & \\cdots\\\\\n",
    "\\cdots & \\cdots & \\cdots & \\cdots\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bef19-1901-4578-97fe-ae68c85a83ba",
   "metadata": {},
   "source": [
    "# Set Initial Conditions\n",
    "I must set the initial $\\textbf x$ and $\\textbf P$.\n",
    "\n",
    "I think I'll just use kriging to interpolate the initial sensor data geospatially. Then, I'll do similar covariance calculations as $\\textbf Q$, stated above, based on whether surrounding squares have sensor values or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8457e35-1ad6-4ba1-87f9-02c1033e8b79",
   "metadata": {},
   "source": [
    "---\n",
    "Ok, so that's all of the math defined. Now, I need to code it. Wahoo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
